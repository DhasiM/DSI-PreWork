{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df56f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1= reading files\n",
    "akas = pd.read_csv('title.akas.tsv', delimiter = \"\\t\", dtype = 'object') #read dtypes as object to optimise memory use\n",
    "akas.head()\n",
    "basics = pd.read_csv('title.basics.tsv', delimiter = '\\t', dtype ='object')\n",
    "basics.head(1)\n",
    "ratings = pd.read_csv('title.ratings.tsv', delimiter = '\\t', dtype='object')\n",
    "ratings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 =Dropping duplicates\n",
    "akas.drop_duplicates()\n",
    "basics.drop_duplicates()\n",
    "ratings.drop_duplicates()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 = Using merge\n",
    "#Q3.1 Inner merge\n",
    "newdf = pd.merge(basics, ratings, on ='tconst', how ='inner')\n",
    "newdf.head(1)\n",
    "movies_mergedInner = pd.merge(akas, newdf, left_on='titleId', right_on='tconst', how ='inner')\n",
    "movies_mergedInner.info()\n",
    "#number of lines 1686547, 19 columns\n",
    "#Q3.1 Outer merge\n",
    "df = pd.merge(basics, ratings, on ='tconst', how ='outer')\n",
    "movies_mergedOuter = pd.merge(akas, df, left_on='titleId', right_on='tconst', how ='outer')\n",
    "movies_mergedOuter.info()\n",
    "#number of lines 3419932, 19 columns\n",
    "#Q3.2 Unique method\n",
    "unique= movies_mergedInner['titleType'].nunique()\n",
    "print('Number of unique values in titleType = ', unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "df_new = movies_mergedOuter[(movies_mergedOuter.titleType=='movie') & \n",
    "                            ((movies_mergedOuter.region=='US') |\n",
    "                             (movies_mergedOuter.language =='en'))]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5 add log10votes to datatframe\n",
    "#Changed object type to integer to enable analysis\n",
    "df_new.numVotes = df_new.numVotes.astype(str).astype(int)\n",
    "df_new['log10Votes'] = np.log10(df_new['numVotes'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6 Lower case of genres column\n",
    "df_new.genres = df_new.genres.str.lower()\n",
    "df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6.1 group by genre and show highest 10 by mean of log10VOtes\n",
    "df1 = df_new.groupby('genres')['log10Votes'].mean().sort_values(ascending=False)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc719ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6.2 group by genre and show highest 10 by mean of averageRating\n",
    "#Changed object type to integer to enable downstream analysis\n",
    "df_new[\"averageRating\"] = df_new[\"averageRating\"].astype(str).astype(float)\n",
    "df2 = df_new.groupby('genres')['averageRating'].mean().sort_values(ascending=False)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c92df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 \n",
    "#Groupby averageRating\n",
    "df2 = df_new.groupby('averageRating').mean().reset_index()\n",
    "#Draw scatterplot of averageRating and log10Votes\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x = df2['averageRating'], y = df2['log10Votes'])\n",
    "plt.title('Scatterplot of averageRating vs log10Votes')\n",
    "plt.xlabel('averageRating')\n",
    "plt.ylabel('log10Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.1 Linear regression with sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#create numpy arrays\n",
    "X = np.array(df2['averageRating']).reshape(-1,1) \n",
    "Y= np.array(df2['log10Votes']).reshape(-1,1)\n",
    "\n",
    "#create regression object\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "#fit regression line\n",
    "reg.fit(X, Y)\n",
    "xfit = np.linspace(1, 10, 1000)\n",
    "yfit = reg.predict(xfit[:, np.newaxis])\n",
    "\n",
    "#plot regression line\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(xfit, yfit, color='red') #fitted line\n",
    "plt.title('Linear regression of averageRating on log10Votes')\n",
    "plt.xlabel('averageRating')\n",
    "plt.ylabel('log10Votes')\n",
    "\n",
    "#print out values for intercept and slope\n",
    "print('Intercept is ;', reg.intercept_)\n",
    "print('Slope is;', reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.2 linear regression using scipy\n",
    "from scipy import stats\n",
    "X = np.array(df2['averageRating']).reshape(1,-1) \n",
    "Y= np.array(df2['log10Votes']).reshape(1,-1)\n",
    "res = stats.linregress(X, Y)\n",
    "#create array of predicted values\n",
    "ypred = (res.intercept + (res.slope*X))\n",
    "\n",
    "#reshape array for plotting\n",
    "yft =np.array(ypred).reshape(-1,1)\n",
    "xvals=np.array(X).reshape(-1,1)\n",
    "\n",
    "#draw plots\n",
    "plt.scatter(X, Y,)\n",
    "plt.plot(xvals, yft, color='red') #fitted line\n",
    "plt.title('Linear regression of averageRating on log10Votes')\n",
    "plt.xlabel('averageRating')\n",
    "plt.ylabel('log10Votes')\n",
    "plt.show()\n",
    "\n",
    "#print out values for slope and intercept\n",
    "print('Intercept is ;', res.intercept)\n",
    "print('Slope is ;', res.slope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea694f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.3 Linear regression with pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Splitting data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1 = np.array(df2['averageRating']).reshape(-1,1) \n",
    "y1= np.array(df2['log10Votes']).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(x1,y1, test_size=0.2, random_state=0)\n",
    "X_train = X_train.astype(np.float32)\n",
    "Y_train = y_train.astype(np.float32)\n",
    "\n",
    "# Setting the seed or random_state for reproducibility\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Defining the model architecture.\n",
    "class LinearRegressionModel(torch.nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LinearRegressionModel, self).__init__() \n",
    "        self.linear = torch.nn.Linear(1, 1)  # this layer of the model has a single neuron, that takes in one scalar input and gives out one scalar output. \n",
    "    def forward(self, x): \n",
    "        y_pred = self.linear(x) \n",
    "        return y_pred \n",
    "\n",
    "# Creating the model\n",
    "model = LinearRegressionModel()\n",
    "print(model)\n",
    "\n",
    "# Defining the Loss Function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Defining the Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005) \n",
    "\n",
    "#COnvert data to Tensors\n",
    "data_x = torch.tensor([[x] for x in X_train], dtype = torch.float)\n",
    "data_y = torch.tensor([[y] for y in Y_train], dtype = torch.float)\n",
    "\n",
    "#Training the model\n",
    "losses = []         # to keep track of the epoch losses \n",
    "slope_list = []     # to keep track of the slope learnt by the model\n",
    "intercept_list = [] # to keep track of the intercept learnt by the model\n",
    "\n",
    "EPOCHS = 11000\n",
    "print('\\nTRAINING...')\n",
    "for epoch in range(EPOCHS):\n",
    "    # Clear the gradients of the optimizer before running the back-propagation\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    # Feeding the input data in the model and getting out the predictions\n",
    "    pred_y = model(data_x)\n",
    "\n",
    "    # Calculating the loss using the model's predictions and the real y values\n",
    "    loss = criterion(pred_y, data_y) \n",
    "\n",
    "    # Back-Propagation\n",
    "    loss.backward() \n",
    "    \n",
    "    # Updating all the trainable parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Appending the loss.item() \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Appending the learnt slope and intercept   \n",
    "    slope_list.append(model.linear.weight.item())\n",
    "    intercept_list.append(model.linear.bias.item())\n",
    "    \n",
    "    # Print out the losses after every 1100 epochs\n",
    "    if (epoch)%1000 == 0:\n",
    "        print('loss: ', loss.item())\n",
    "        \n",
    "# Plotting the epoch losses (curve must flatten out if training epochs enough)\n",
    "plt.plot(losses)\n",
    "plt.title('Loss VS Epoch')\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "#Printing parameters\n",
    "print(\"Intercept is  ;\", intercept_list[-1])\n",
    "print(\"Slope is ;\", slope_list[-1])\n",
    "\n",
    "#Plotting linear regression line\n",
    "#making predictions\n",
    "pred_y = model(data_x)\n",
    "\n",
    "#creating numpy array and reshaping\n",
    "preds= pred_y.detach().numpy()\n",
    "predy= np.array(preds).reshape(-1,1)\n",
    "dataX=data_x.detach().numpy()\n",
    "dat=np.array(dataX).reshape(-1,1)\n",
    "#drawing plot\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.plot(dat, predy, color='red')\n",
    "plt.title('Linear regression of averageRating on log10Votes')\n",
    "plt.xlabel(\"averageRating\")\n",
    "plt.ylabel('log10Votes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fadf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing Interecept and slope from all three models\n",
    "print('Sklearn Intercept is ;', reg.intercept_)\n",
    "print('Scipy Intercept is ;', res.intercept)\n",
    "print(\"Pytorch Intercept is  ;\", intercept_list[-1])\n",
    "print('SkLearn Slope is;', reg.coef_)\n",
    "print('SciPy Slope is ;', res.slope)\n",
    "print(\"PyTorch Slope is ;\", slope_list[-1])\n",
    "#slight variation in output from PyTorch due to differences in how the regression model is implemented by deeplearning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52592e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
